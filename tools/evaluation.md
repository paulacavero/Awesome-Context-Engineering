

### [Promptfoo](https://github.com/promptfoo/promptfoo) â€“ Prompt evaluation framework  
Compare prompt and context variants with metrics, A/B testing, and model scoring.  
ðŸ’¡ Ideal for testing context effectiveness and optimizing prompt strategies. OSS (MIT).


### [BetterPrompt](https://github.com/stjordanis/betterprompt) â€“ Prompt optimization via evaluation  
Evaluates multiple prompts to identify the best performer using human or automated scoring.  
ðŸ’¡ Useful for optimizing instructions and testing context effectiveness. OSS (MIT).


### [Guardrails AI](https://github.com/guardrails-ai/guardrails) â€“ Output validation for LLMs  
Define rules to validate, fix or reject model outputs using YAML specs. Ensures structure, constraints, and format integrity.  
ðŸ’¡ Great for enforcing safe and correct outputs in context-sensitive flows. OSS (Apache 2.0).


### [adversarialâ€‘prompts](https://github.com/hwchase17/adversarial-prompts) â€“ Curated adversarial prompts  
A collection of prompts that succeed in bypassing or breaking LLM guardrails (evasion, injection, context leakage), with examples and defenses.  
ðŸ’¡ Useful for testing model robustness and evaluating context safety. OSS (MIT).


### [LangSmith](https://docs.smith.langchain.com/evaluation) â€“ Evals framework & dataset testing  
Run structured evaluations (automatic or human feedback) on prompts, RAG pipelines, and agents.  
ðŸ’¡ Great for benchmarking context strategies and regression testing. Free tier.


### [OpenICL](https://github.com/Shark-NLP/OpenICL) â€“ Context evaluation & benchmarking  
Includes inferencers and evaluators (e.g. `AccEvaluator`) to assess prompt/context pipelines over datasets.  
ðŸ’¡ Great for benchmarking prompt quality and in-context performance. OSS (Apacheâ€‘2.0).


### [PromptBench](https://github.com/microsoft/promptbench) â€“ Unified LLM evaluation framework  
Benchmark prompts and LLMs with standard datasets, adversarial attacks, dynamic evaluation (DyVal), and PromptEval strategies.  
ðŸ’¡ Comprehensive tool for testing prompt and context effectiveness. OSS (MIT).
