### [StreamingLLM](https://github.com/mit-han-lab/streaming-llm) â€“ Extend context to streaming lengths  
Efficient pipeline for handling millions of tokens using attention sinks and streaming context.  
ðŸ’¡ Ideal for long-running dialogues with large context windows. OSS (MIT).


### [Dust](https://github.com/dust-tt/dust) â€“ Build real-time LLM apps  
Create streaming LLM pipelines with stateful blocks, external tools, and dynamic context.  
ðŸ’¡ Great for interactive flows and chat-based apps. OSS.


### [LangChain streaming](https://python.langchain.com/docs/how_to/chat_streaming/) â€“ Token streaming support  
Integrated support for streaming token-by-token responses with callbacks in LangChain.  
ðŸ’¡ Perfect for building responsive UIs and dynamic chat. OSS.
